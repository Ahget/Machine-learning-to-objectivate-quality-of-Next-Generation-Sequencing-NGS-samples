{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline de l'étude, divisant la base de données en ensemble d'entraînement (afin d'entraîner les modèles) et en ensemble de test (sur lequel le modèle sera évalué)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation des DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all file paths\n",
    "from glob import glob\n",
    "paths = glob(r\"C:\\Users\\ahmed\\MFE project\\Final\\**\", recursive= True)\n",
    "\n",
    "pathy = [i for i in paths if (len(i)>=120) & (i[-3:]!=\"pdf\")]\n",
    "pathy_amplicon = [i for i in pathy if i[-16:-8]==\"amplicon\"]\n",
    "\n",
    "pathys = [i for i in paths if (i[-3:]!=\"pdf\") & (len(i)>60) & (i.find(\"bcmatrix\")<0)]\n",
    "pathy_tsv = [i for i in pathys if i[-3:]==\"tsv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#préparation du tsv\n",
    "\n",
    "def extract_info_tsv(path):\n",
    "    split = path.split('\\\\')\n",
    "    annee = split[5]\n",
    "    sp = split[6]\n",
    "    spi = sp.replace('_', '-')\n",
    "    spl = spi.split('-')\n",
    "    type = 0\n",
    "    date = 0\n",
    "    num = 0\n",
    "    if len(spl)==5:\n",
    "        type = spl[0]\n",
    "        date = '-'.join(spl[1:-1])\n",
    "        num = spl[-1]\n",
    "    if len(spl)==6:\n",
    "        type = spl[0]\n",
    "        date = spl[2]\n",
    "        num = spl[-1]\n",
    "    classe = split[7]\n",
    "    return [annee, type, date, num, classe]\n",
    "\n",
    "def create_TSV(pathy_tsv):\n",
    "    caract = [\"annee\", \"type\", \"date\", \"num\", \"classe\"]\n",
    "    df_list=[]\n",
    "    for j in range(len(pathy_tsv)):\n",
    "        path = pathy_tsv[j]\n",
    "        dfa = pd.read_csv(path, sep='\\t')\n",
    "        if str(dfa[\"Barcode\"][0])!=\"nan\":\n",
    "            df1 = dfa[dfa[\"Barcode\"]==dfa[\"Barcode\"][0]]\n",
    "            df1.index = range(len(df1))\n",
    "            cara = extract_info_tsv(path)\n",
    "            for i in range(len(caract)):\n",
    "                df1.loc[:,caract[i]]= cara[i]\n",
    "            df1.loc[:,'ordre'] = j\n",
    "            df1.loc[:,\"longueur\"] = len(df1)\n",
    "            df_list.append(df1)\n",
    "    df_tsv = pd.concat(df_list)\n",
    "    df_tsv.index = range(len(df_tsv))\n",
    "    df_tsv = df_tsv.replace(\"NAV\", \"NVA\")\n",
    "    df_tsv = df_tsv.replace(\"nva\", \"NVA\")\n",
    "    return df_tsv.fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparation du amplicon\n",
    "def extract_info_amplicon(path):\n",
    "    split = path.split('\\\\')\n",
    "    annee = split[5]\n",
    "    sp = split[6]\n",
    "    spi = sp.replace('_', '-')\n",
    "    spl = spi.split('-')\n",
    "    type = 0\n",
    "    date = 0\n",
    "    num = 0\n",
    "    if len(spl)==5:\n",
    "        type = spl[0]\n",
    "        date = '-'.join(spl[1:-1])\n",
    "        num = spl[-1]\n",
    "    if len(spl)==6:\n",
    "        type = spl[0]\n",
    "        date = spl[2]\n",
    "        num = spl[-1]\n",
    "    classe = split[7]\n",
    "    num2 = split[-1].split('_')[1]\n",
    "    num3 = split[-1].split('_')[-1][:-17]\n",
    "    return [annee, type, date, num, classe, num2, num3]\n",
    "\n",
    "def create_amplicon(pathy_amplicon):\n",
    "    caract = [\"annee\", \"type\", \"date\", \"num\", \"classe\", \"num2\", \"num3\"]\n",
    "    df_list=[]\n",
    "    for j in range(len(pathy_amplicon)):\n",
    "        path = pathy_amplicon[j]\n",
    "        df1 = pd.read_csv(path, sep='\\t')\n",
    "        cara = extract_info_amplicon(path)\n",
    "        for i in range(len(caract)):\n",
    "            df1.loc[:,caract[i]]= cara[i]\n",
    "        df1.loc[:,'ordre'] = j\n",
    "        df1.loc[:, \"longueur\"] = len(df1)\n",
    "        df_list.append(df1)\n",
    "    df_amplicon = pd.concat(df_list)\n",
    "    df_amplicon.index = range(len(df_amplicon))\n",
    "    df_amplicon = df_amplicon.replace(\"NAV\", \"NVA\")\n",
    "    df_amplicon = df_amplicon.replace(\"nva\", \"NVA\")\n",
    "    df_amplicon.loc[:, \"contig_length\"] = df_amplicon[\"contig_end\"] - df_amplicon[\"contig_srt\"]+1\n",
    "    df_amplicon.loc[:, \"gc_percent\"] = df_amplicon[\"gc_count\"]/df_amplicon[\"contig_length\"]\n",
    "    df_amplicon.loc[:, \"cov20_percent\"] = df_amplicon[\"cov20x\"]/df_amplicon[\"contig_length\"]\n",
    "    df_amplicon.loc[:, \"cov100_percent\"] = df_amplicon[\"cov100x\"]/df_amplicon[\"contig_length\"]\n",
    "    df_amplicon.loc[:, \"cov500_percent\"] = df_amplicon[\"cov500x\"]/df_amplicon[\"contig_length\"]\n",
    "    df_amplicon.loc[:, \"fwd_e2e_percent\"] = df_amplicon[\"fwd_e2e\"]/df_amplicon[\"fwd_reads\"]\n",
    "    df_amplicon.loc[:, \"rev_e2e_percent\"] = df_amplicon[\"rev_e2e\"]/df_amplicon[\"rev_reads\"]\n",
    "    return df_amplicon.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour avoir une df avec les infos et les ordres. afin de pouvoir bien les séparer pour le k-fold.\n",
    "def get_df_info_amplicon(pathy_amplicon):\n",
    "    df_list=[]\n",
    "    for j in range(len(pathy_amplicon)):\n",
    "        info = extract_info_amplicon(pathy_amplicon[j])\n",
    "        info.append(j)\n",
    "        df_info = pd.DataFrame([info], columns=[\"annee\", \"type\", \"date\", \"num\", \"classe\", \"num2\", \"num3\", \"ordre\"])\n",
    "        df_list.append(df_info)\n",
    "    df_am = pd.concat(df_list)\n",
    "    df_am.index = range(len(df_am))\n",
    "    df_am = df_am.replace(\"NAV\", \"NVA\")\n",
    "    df_am = df_am.replace(\"nva\", \"NVA\")\n",
    "    return df_am\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérifier si un type de cancer a une distribution différentes des autres en terme de qualité.\n",
    "#nombres/type: 186, 108, 230, 21, 41, 12\n",
    "liste = [\"CVC\", \"OBL\", \"NDN\", \"TM\", \"BAL\", \"BM\"]\n",
    "lis = []\n",
    "for li in liste:\n",
    "    k = []\n",
    "    ok = df_am[df_am[\"type\"]==li]\n",
    "    k.append(len(ok[ok[\"classe\"]==\"OPT\"])/len(ok))\n",
    "    k.append(len(ok[ok[\"classe\"]==\"NC\"])/len(ok))\n",
    "    k.append(len(ok[ok[\"classe\"]==\"SOPT\"])/len(ok))\n",
    "    k.append(len(ok[ok[\"classe\"]==\"NVA\"])/len(ok))\n",
    "    lis.append(k)\n",
    "df_lis = pd.DataFrame(lis, columns=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"], index=liste)\n",
    "\n",
    "df_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "DF_tsv = create_TSV(pathy_tsv)\n",
    "DF_amplicon = create_amplicon(pathy_amplicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRAI K-FOLD\n",
    "\n",
    "#pipelining intégrant le kfold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "def create_df_kfold(df, df_am, carac):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    index_train = []\n",
    "    index_test = []\n",
    "    for train_index, test_index in skf.split(df_am[\"ordre\"], df_am[carac]):\n",
    "        index_train.append(train_index)\n",
    "        index_test.append(test_index)\n",
    "    return index_train, index_test\n",
    "\n",
    "def split_amplicon_train_test(df, index_train, index_test):\n",
    "    df_train = pd.concat([df[df[\"ordre\"]==i] for i in index_train])\n",
    "    df_train.index = range(len(df_train))\n",
    "\n",
    "    df_test = pd.concat([df[df[\"ordre\"]==i] for i in index_test])\n",
    "    df_test.index = range(len(df_test))\n",
    "    return df_train, df_test\n",
    "\n",
    "#normaliser le train puis l'appliquer au test\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def norm_split_tsv_train_test(df_tsv, lis_train, lis_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    train = pd.concat([df_tsv[df_tsv[\"ordre\"]==i] for i in lis_train])\n",
    "    train.index = range(len(train))\n",
    "    test = pd.concat([df_tsv[df_tsv[\"ordre\"]==i] for i in lis_test])\n",
    "    test.index = range(len(test))\n",
    "    train_norm = scaler.fit_transform(train[[\"Frequency\", \"Quality\", \"Coverage\", \"Allele Cov\", \"longueur\"]])\n",
    "    train_norm = pd.concat([train, pd.DataFrame(train_norm, columns = [\"Frequency_norm\", \"Quality_norm\", \"Coverage_norm\", \"Allele Cov_norm\", \"longueur_norm\"])], axis = 1)\n",
    "    test_norm = scaler.transform(test[[\"Frequency\", \"Quality\", \"Coverage\", \"Allele Cov\", \"longueur\"]])\n",
    "    test_norm = pd.concat([test, pd.DataFrame(test_norm, columns = [\"Frequency_norm\", \"Quality_norm\", \"Coverage_norm\", \"Allele Cov_norm\", \"longueur_norm\"])], axis = 1)\n",
    "    return train_norm, test_norm\n",
    "\n",
    "def pred2class(df_train, df_test, clf):\n",
    "    New_var1 = ['gc_percent', 'cov500_percent', 'fwd_e2e_percent', 'rev_e2e_percent', 'cov20_percent', 'cov100_percent', 'contig_length']\n",
    "    train_2class = df_train[(df_train[\"classe\"]==\"OPT\")|(df_train[\"classe\"]==\"NC\")]\n",
    "    clf.fit(train_2class[New_var1], train_2class[\"classe\"])\n",
    "    pred_train = clf.predict(df_train[New_var1])\n",
    "    pred_test = clf.predict(df_test[New_var1])\n",
    "    df_train.loc[:,\"pred2class\"] = pred_train\n",
    "    df_test.loc[:,\"pred2class\"] = pred_test\n",
    "    return df_train, df_test\n",
    "\n",
    "def train_test_amp_tsv(df_amp, df_tsv, lis_train, lis_test, clf):\n",
    "    train, test = split_amplicon_train_test(df_amp, lis_train, lis_test)\n",
    "    tsv_train_norm, tsv_test_norm = norm_split_tsv_train_test(df_tsv, lis_train, lis_test)\n",
    "    df_amp_train, df_amp_test = pred2class(train, test, clf)\n",
    "    return df_amp_train, df_amp_test, tsv_train_norm, tsv_test_norm\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on normalise et ajoute des features. On sépare aussi le test et train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en prenant au hasard -----> FAUX K-FOLD\n",
    "\n",
    "# split dataframe into one train sample and one test sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split_df_test_train(df, carac, percent):\n",
    "    if carac == \"type\":\n",
    "        liste = [\"CVC\", \"OBL\", \"NDN\", \"TM\", \"BAL\", \"BM\"]\n",
    "    if carac == \"classe\":\n",
    "        liste = [\"OPT\", \"NC\", \"SOPT\", \"NVA\"]\n",
    "    ordre_train= []\n",
    "    ordre_test=[]\n",
    "    for i in liste:\n",
    "        df_typ = df[df[carac]==i]\n",
    "        lis = list(dict.fromkeys(df_typ[\"ordre\"].values))\n",
    "        lis_train, lis_test = train_test_split(lis, test_size=percent, shuffle = True)\n",
    "        ordre_train.extend(lis_train)\n",
    "        ordre_test.extend(lis_test)\n",
    "\n",
    "    df_train = pd.concat([df[df[\"ordre\"]==i] for i in ordre_train])\n",
    "    df_train.index = range(len(df_train))\n",
    "\n",
    "    df_test = pd.concat([df[df[\"ordre\"]==i] for i in ordre_test])\n",
    "    df_test.index = range(len(df_test))\n",
    "\n",
    "    return df_train, df_test, ordre_train, ordre_test\n",
    "\n",
    "#normaliser le train puis l'appliquer au test\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# def norm_split_tsv_train_test(df_tsv, lis_train, lis_test):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     train = pd.concat([df_tsv[df_tsv[\"ordre\"]==i] for i in lis_train])\n",
    "#     train.index = range(len(train))\n",
    "#     test = pd.concat([df_tsv[df_tsv[\"ordre\"]==i] for i in lis_test])\n",
    "#     test.index = range(len(test))\n",
    "#     train_norm = scaler.fit_transform(train[[\"Frequency\", \"Quality\", \"Coverage\", \"Allele Cov\", \"longueur\"]])\n",
    "#     train_norm = pd.concat([train, pd.DataFrame(train_norm, columns = [\"Frequency_norm\", \"Quality_norm\", \"Coverage_norm\", \"Allele Cov_norm\", \"longueur_norm\"])], axis = 1)\n",
    "#     test_norm = scaler.transform(test[[\"Frequency\", \"Quality\", \"Coverage\", \"Allele Cov\", \"longueur\"]])\n",
    "#     test_norm = pd.concat([test, pd.DataFrame(test_norm, columns = [\"Frequency_norm\", \"Quality_norm\", \"Coverage_norm\", \"Allele Cov_norm\", \"longueur_norm\"])], axis = 1)\n",
    "#     return train_norm, test_norm\n",
    "\n",
    "# def pred2class(df_train, df_test, clf):\n",
    "#     New_var1 = ['gc_percent', 'cov500_percent', 'fwd_e2e_percent', 'rev_e2e_percent', 'cov20_percent', 'cov100_percent', 'contig_length']\n",
    "#     train_2class = df_train[(df_train[\"classe\"]==\"OPT\")|(df_train[\"classe\"]==\"NC\")]\n",
    "#     clf.fit(train_2class[New_var1], train_2class[\"classe\"])\n",
    "#     pred_train = clf.predict(df_train[New_var1])\n",
    "#     pred_test = clf.predict(df_test[New_var1])\n",
    "#     df_train.loc[:,\"pred2class\"] = pred_train\n",
    "#     df_test.loc[:,\"pred2class\"] = pred_test\n",
    "#     return df_train, df_test\n",
    "\n",
    "# def train_test_amp_tsv(df_amp, df_tsv, carac, percent, clf):\n",
    "#     train, test, lis_train, lis_test = split_df_test_train(df_amp, carac, percent)\n",
    "#     tsv_train_norm, tsv_test_norm = norm_split_tsv_train_test(df_tsv, lis_train, lis_test)\n",
    "#     df_amp_train, df_amp_test = pred2class(train, test, clf)\n",
    "#     return df_amp_train, df_amp_test, tsv_train_norm, tsv_test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prédiction 2 classes, en local\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf =DecisionTreeClassifier(min_samples_leaf=17,max_depth= 10, min_samples_split= 9)\n",
    "\n",
    "# df_amp_train, df_amp_test, df_tsv_train, df_tsv_test = train_test_amp_tsv(DF_amplicon, DF_tsv, \"type\", 0.3, clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les fichiers locaux et leurs variables locales sont faites (tsv normé, 6 nouvelles features pour amplicon + la prédiction 2 classes).\n",
    "\n",
    "Passons maintenant aux variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# des fonctions pour extraire les variables globales\n",
    "def Extract_glob_feat(df, feat, longueur):\n",
    "    nume = []\n",
    "    nume.append(np.array([1 for i in df[feat].values if i>0.3]).sum()/longueur)\n",
    "    nume.append(np.array([1 for i in df[feat].values if i>0.5]).sum()/longueur)\n",
    "    nume.append(np.array([1 for i in df[feat].values if i>0.7]).sum()/longueur)\n",
    "    nume.append(np.array([1 for i in df[feat].values if i>0.9]).sum()/longueur)\n",
    "    df_res = pd.DataFrame(data = [[df[feat].mean(), df[feat].median(), nume[0], nume[1], nume[2], nume[3]]] , columns = [feat+\"_mean\", feat+\"_median\", feat+\"_\"+str(0.3), feat+\"_\"+str(0.5), feat+\"_\"+str(0.7), feat+\"_\"+str(0.9)])\n",
    "    return df_res\n",
    "    \n",
    "def extract_all_var(df, variables, longueur):\n",
    "    list_df = []\n",
    "    for feat in variables:\n",
    "        df_t = Extract_glob_feat(df, feat, longueur)\n",
    "        list_df.append(df_t)\n",
    "    df_tot = pd.concat(list_df, axis = 1)\n",
    "    return df_tot\n",
    "\n",
    "def create_var_glob_amplicon(df_amp):\n",
    "    var_percent = ['gc_percent', 'cov20_percent', 'cov100_percent', 'cov500_percent', 'fwd_e2e_percent', 'rev_e2e_percent']\n",
    "    ordr = list(dict.fromkeys(df_amp[\"ordre\"].values))\n",
    "    resultat = []\n",
    "\n",
    "    for i in ordr:\n",
    "        df_tru = df_amp[df_amp[\"ordre\"]==i]\n",
    "        longueur = df_tru[\"longueur\"].values[0]\n",
    "    # information des variables en pourcent\n",
    "        df_var = extract_all_var(df_tru, var_percent, longueur)\n",
    "\n",
    "    # information sur la classe\n",
    "        df_var.loc[:,\"ordre\"] = i\n",
    "        df_var.loc[:, \"type\"] = df_tru[\"type\"].values[0]\n",
    "        df_var.loc[:, \"date\"] = df_tru[\"date\"].values[0]\n",
    "        df_var.loc[:, \"classe\"] = df_tru[\"classe\"].values[0]\n",
    "        df_var.loc[:, \"num2\"] = df_tru[\"num2\"].values[0]\n",
    "        df_var.loc[:, \"longueur\"] = longueur\n",
    "\n",
    "    # varible globale % de OPT\n",
    "        OPT = np.array([1 for i in range(len(df_tru)) if df_tru[\"pred2class\"].values[i]==\"OPT\"]).sum()\n",
    "        OPT_percent = OPT/longueur\n",
    "\n",
    "        df_var.loc[:, \"OPT_percent\"] = OPT_percent\n",
    "\n",
    "    # création de la base de données / CSV\n",
    "        resultat.append(df_var)\n",
    "    df_resul = pd.concat(resultat)\n",
    "    df_resul.index = range(len(df_resul))\n",
    "    return df_resul\n",
    "\n",
    "def create_var_glob_tsv(df_tsv):\n",
    "    var_percent = ['Frequency_norm', 'Quality_norm', 'Coverage_norm', 'Allele Cov_norm', 'longueur_norm']\n",
    "    ordr = list(dict.fromkeys(df_tsv[\"ordre\"].values))\n",
    "    resultat = []\n",
    "\n",
    "    for i in ordr:\n",
    "        df_tru = df_tsv[df_tsv[\"ordre\"]==i]\n",
    "        longueur = df_tru[\"longueur\"].values[0]\n",
    "# information des variables en pourcent\n",
    "        df_var = extract_all_var(df_tru, var_percent, longueur)\n",
    "\n",
    "# création de la base de données / CSV\n",
    "        resultat.append(df_var)\n",
    "    df_resul = pd.concat(resultat)\n",
    "    df_resul.index = range(len(df_resul))\n",
    "    return df_resul\n",
    "\n",
    "def create_var_glob_tot(df_amp, df_tsv):\n",
    "    df_amp_glob = create_var_glob_amplicon(df_amp)\n",
    "    df_tsv_glob = create_var_glob_tsv(df_tsv)\n",
    "    df_global = pd.concat([df_amp_glob, df_tsv_glob], axis = 1)\n",
    "    return df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = create_var_glob_tot(df_amp_train, df_tsv_train)\n",
    "# test = create_var_glob_tot(df_amp_test, df_tsv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(liste):\n",
    "    if liste == \"all\":\n",
    "        features = ['gc_percent_mean', 'gc_percent_median',\n",
    "       'gc_percent_0.3', 'gc_percent_0.5', 'gc_percent_0.7', 'gc_percent_0.9',\n",
    "       'cov20_percent_mean', 'cov20_percent_median', 'cov20_percent_0.3',\n",
    "       'cov20_percent_0.5', 'cov20_percent_0.7', 'cov20_percent_0.9',\n",
    "       'cov100_percent_mean', 'cov100_percent_median', 'cov100_percent_0.3',\n",
    "       'cov100_percent_0.5', 'cov100_percent_0.7', 'cov100_percent_0.9',\n",
    "       'cov500_percent_mean', 'cov500_percent_median', 'cov500_percent_0.3',\n",
    "       'cov500_percent_0.5', 'cov500_percent_0.7', 'cov500_percent_0.9',\n",
    "       'fwd_e2e_percent_mean', 'fwd_e2e_percent_median', 'fwd_e2e_percent_0.3',\n",
    "       'fwd_e2e_percent_0.5', 'fwd_e2e_percent_0.7', 'fwd_e2e_percent_0.9',\n",
    "       'rev_e2e_percent_mean', 'rev_e2e_percent_median', 'rev_e2e_percent_0.3',\n",
    "       'rev_e2e_percent_0.5', 'rev_e2e_percent_0.7', 'rev_e2e_percent_0.9', 'longueur', 'OPT_percent',\n",
    "       'Frequency_norm_mean', 'Frequency_norm_median', 'Frequency_norm_0.3',\n",
    "       'Frequency_norm_0.5', 'Frequency_norm_0.7', 'Frequency_norm_0.9',\n",
    "       'Quality_norm_mean', 'Quality_norm_median', 'Quality_norm_0.3',\n",
    "       'Quality_norm_0.5', 'Quality_norm_0.7', 'Quality_norm_0.9',\n",
    "       'Coverage_norm_mean', 'Coverage_norm_median', 'Coverage_norm_0.3',\n",
    "       'Coverage_norm_0.5', 'Coverage_norm_0.7', 'Coverage_norm_0.9',\n",
    "       'Allele Cov_norm_mean', 'Allele Cov_norm_median', 'Allele Cov_norm_0.3',\n",
    "       'Allele Cov_norm_0.5', 'Allele Cov_norm_0.7', 'Allele Cov_norm_0.9',\n",
    "       'longueur_norm_mean', 'longueur_norm_median', 'longueur_norm_0.3',\n",
    "       'longueur_norm_0.5', 'longueur_norm_0.7', 'longueur_norm_0.9']\n",
    "\n",
    "    elif liste == \"amplicon\":\n",
    "        features = ['gc_percent_mean', 'gc_percent_median',\n",
    "       'gc_percent_0.3', 'gc_percent_0.5', 'gc_percent_0.7', 'gc_percent_0.9',\n",
    "       'cov20_percent_mean', 'cov20_percent_median', 'cov20_percent_0.3',\n",
    "       'cov20_percent_0.5', 'cov20_percent_0.7', 'cov20_percent_0.9',\n",
    "       'cov100_percent_mean', 'cov100_percent_median', 'cov100_percent_0.3',\n",
    "       'cov100_percent_0.5', 'cov100_percent_0.7', 'cov100_percent_0.9',\n",
    "       'cov500_percent_mean', 'cov500_percent_median', 'cov500_percent_0.3',\n",
    "       'cov500_percent_0.5', 'cov500_percent_0.7', 'cov500_percent_0.9',\n",
    "       'fwd_e2e_percent_mean', 'fwd_e2e_percent_median', 'fwd_e2e_percent_0.3',\n",
    "       'fwd_e2e_percent_0.5', 'fwd_e2e_percent_0.7', 'fwd_e2e_percent_0.9',\n",
    "       'rev_e2e_percent_mean', 'rev_e2e_percent_median', 'rev_e2e_percent_0.3',\n",
    "       'rev_e2e_percent_0.5', 'rev_e2e_percent_0.7', 'rev_e2e_percent_0.9', 'longueur', 'OPT_percent']\n",
    "    \n",
    "    elif liste == \"tsv\":\n",
    "        features = ['Frequency_norm_mean', 'Frequency_norm_median', 'Frequency_norm_0.3',\n",
    "       'Frequency_norm_0.5', 'Frequency_norm_0.7', 'Frequency_norm_0.9',\n",
    "       'Quality_norm_mean', 'Quality_norm_median', 'Quality_norm_0.3',\n",
    "       'Quality_norm_0.5', 'Quality_norm_0.7', 'Quality_norm_0.9',\n",
    "       'Coverage_norm_mean', 'Coverage_norm_median', 'Coverage_norm_0.3',\n",
    "       'Coverage_norm_0.5', 'Coverage_norm_0.7', 'Coverage_norm_0.9',\n",
    "       'Allele Cov_norm_mean', 'Allele Cov_norm_median', 'Allele Cov_norm_0.3',\n",
    "       'Allele Cov_norm_0.5', 'Allele Cov_norm_0.7', 'Allele Cov_norm_0.9',\n",
    "       'longueur_norm_mean', 'longueur_norm_median', 'longueur_norm_0.3',\n",
    "       'longueur_norm_0.5', 'longueur_norm_0.7', 'longueur_norm_0.9']\n",
    "\n",
    "    elif liste == \"Pearson\":\n",
    "        features = ['gc_percent_mean', 'gc_percent_0.7',\n",
    "       'cov20_percent_mean', 'cov20_percent_median', 'cov100_percent_mean',\n",
    "       'fwd_e2e_percent_mean', 'fwd_e2e_percent_median', 'fwd_e2e_percent_0.3',\n",
    "       'fwd_e2e_percent_0.9', 'OPT_percent', 'longueur',\n",
    "       'Frequency_norm_mean', 'Frequency_norm_0.7',\n",
    "       'Quality_norm_mean', 'Quality_norm_0.7', 'Quality_norm_0.9',\n",
    "       'Coverage_norm_mean','Coverage_norm_0.9',\n",
    "       'longueur_norm_mean', 'longueur_norm_0.3',\n",
    "       'longueur_norm_0.5', 'longueur_norm_0.7']\n",
    "\n",
    "    elif liste == \"Spearman\":\n",
    "        features = ['gc_percent_mean',\n",
    "       'gc_percent_0.3', 'gc_percent_0.5', 'gc_percent_0.9',\n",
    "       'cov20_percent_mean', 'cov20_percent_median', 'cov100_percent_mean', 'cov100_percent_median',\n",
    "       'cov500_percent_median', 'fwd_e2e_percent_mean', 'fwd_e2e_percent_median', 'fwd_e2e_percent_0.3',\n",
    "       'fwd_e2e_percent_0.5', 'fwd_e2e_percent_0.7', 'fwd_e2e_percent_0.9',\n",
    "       'rev_e2e_percent_mean', 'rev_e2e_percent_0.3',\n",
    "       'rev_e2e_percent_0.5', 'rev_e2e_percent_0.7', 'rev_e2e_percent_0.9', 'longueur', 'OPT_percent',\n",
    "       'Frequency_norm_mean', 'Frequency_norm_0.3',\n",
    "       'Quality_norm_mean',\n",
    "       'Quality_norm_0.5', 'Quality_norm_0.7', 'Quality_norm_0.9',\n",
    "       'Coverage_norm_mean',\n",
    "       'longueur_norm_mean', 'longueur_norm_0.3',\n",
    "       'longueur_norm_0.5', 'longueur_norm_0.7', 'longueur_norm_0.9']\n",
    "    \n",
    "    elif liste == \"rfe\":\n",
    "        features = ['cov100_percent_0.9', 'cov500_percent_mean', 'cov500_percent_0.3',\n",
    "       'cov500_percent_0.5', 'cov500_percent_0.7', 'cov500_percent_0.9',\n",
    "       'OPT_percent', 'Frequency_norm_mean', 'Frequency_norm_median',\n",
    "       'Frequency_norm_0.3', 'Frequency_norm_0.5', 'Quality_norm_mean',\n",
    "       'Quality_norm_median', 'Quality_norm_0.3', 'Coverage_norm_mean',\n",
    "       'Coverage_norm_median', 'Coverage_norm_0.3', 'Coverage_norm_0.5',\n",
    "       'Coverage_norm_0.7', 'Coverage_norm_0.9', 'Allele Cov_norm_mean',\n",
    "       'Allele Cov_norm_median', 'Allele Cov_norm_0.9',\n",
    "       'longueur_norm_mean', 'longueur_norm_median']\n",
    "\n",
    "    elif liste == \"rf\":\n",
    "        features = ['cov100_percent_mean', 'Coverage_norm_0.9', 'Frequency_norm_median',\n",
    "       'Coverage_norm_0.7', 'cov500_percent_median', 'Quality_norm_mean',\n",
    "       'Quality_norm_0.3', 'Allele Cov_norm_0.3', 'Coverage_norm_0.3',\n",
    "       'Frequency_norm_mean', 'longueur_norm_median', 'Coverage_norm_0.5',\n",
    "       'Frequency_norm_0.3', 'cov500_percent_0.9', 'cov500_percent_mean',\n",
    "       'longueur_norm_mean', 'Allele Cov_norm_mean', 'Coverage_norm_median',\n",
    "       'Coverage_norm_mean', 'cov500_percent_0.5', 'cov500_percent_0.7',\n",
    "       'Quality_norm_median', 'Allele Cov_norm_median', 'cov500_percent_0.3',\n",
    "       'OPT_percent']\n",
    "\n",
    "    return features\n",
    "\n",
    "#RFE\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import RFE\n",
    "# estim = RandomForestClassifier(n_estimators=50)\n",
    "# rfe = RFE(estim, n_features_to_select=25, step=1)\n",
    "# rfe = rfe.fit(train[select_features(\"all\")], train[\"classe\"])\n",
    "# feat_imp = pd.concat([pd.DataFrame(rfe.support_, columns=[\"imp\"]),pd.DataFrame(select_features(\"all\"), columns=[\"feat\"])], axis=1)\n",
    "# feat_rfe = feat_imp[feat_imp[\"imp\"]==True][\"feat\"].values\n",
    "# feat_rfe\n",
    "\n",
    "#RF\n",
    "# feat_imprf = pd.DataFrame(clf.feature_importances_, index=select_features(\"all\"))\n",
    "# feat_imprf.sort_values(0)[-25:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1score(mat):\n",
    "    res = []\n",
    "    for i in range(len(mat)):\n",
    "        precision = mat[i][i]/np.sum([j[i] for j in mat])\n",
    "        recall = mat[i][i]/np.sum(mat[i])\n",
    "        F1 = (2 * precision * recall)/(precision + recall)\n",
    "        res.append(F1)\n",
    "    return res\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def macnemar(preda, predb, groundtruth):\n",
    "    Ta = preda==groundtruth\n",
    "    Tb = predb==groundtruth\n",
    "\n",
    "    a = ((Ta==True)*(Tb==True)).sum()\n",
    "    b = ((Ta==True)*(Tb==False)).sum()\n",
    "    c = ((Ta==False)*(Tb==True)).sum()\n",
    "    d = ((Ta==False)*(Tb==False)).sum()\n",
    "\n",
    "    ct = [[a,b], [c,d]]\n",
    "\n",
    "    m = mcnemar(ct, exact=True)\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators= 50)\n",
    "\n",
    "def get_pred(train, test, clf):\n",
    "    feats = [\"all\", \"amplicon\", \"tsv\", \"Pearson\", \"Spearman\", \"rfe\", \"rf\"]\n",
    "    resu = []\n",
    "    for feat in feats:\n",
    "        clf.fit(train[select_features(feat)], train[\"classe\"])\n",
    "        pred = pd.DataFrame(clf.predict(test[select_features(feat)]), columns=[\"pred_\"+feat])\n",
    "        resu.append(pred)\n",
    "    resus = pd.concat(resu, axis=1)\n",
    "    resus.loc[:, \"classe\"] = test[\"classe\"]\n",
    "    return resus\n",
    "\n",
    "# def k_fold(DF_amplicon, DF_tsv, DT, clf, num):\n",
    "#     resultats = []\n",
    "#     for nu in range(num):\n",
    "#         df_amp_train, df_amp_test, df_tsv_train, df_tsv_test = train_test_amp_tsv(DF_amplicon, DF_tsv, \"classe\", 0.3, DT)\n",
    "\n",
    "#         #création des databases finales\n",
    "#         train = create_var_glob_tot(df_amp_train, df_tsv_train)\n",
    "#         test = create_var_glob_tot(df_amp_test, df_tsv_test)\n",
    "#         pre = get_pred(train, test, clf)                           méthode inappropriée\n",
    "#         pre.loc[:, \"num\"]=nu\n",
    "#         resultats.append(pre)\n",
    "#     res = pd.concat(resultats)\n",
    "#     res.index = range(len(res))\n",
    "#     return res\n",
    "\n",
    "# def get_metrics(pre):\n",
    "#     res_f1 = []\n",
    "#     res_F1n = []\n",
    "#     results =[]\n",
    "#     for num in range(pre[\"num\"].values[-1]+1):\n",
    "        \n",
    "#         pred = pre[pre[\"num\"]==num]\n",
    "#         columns = pred.columns[:-2]\n",
    "#         for feat in columns:\n",
    "#             mat = confusion_matrix(pred[\"classe\"], pred[feat], normalize=\"true\", labels=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"])\n",
    "#             F1 = F1score(mat)\n",
    "#             df_F1 = pd.DataFrame(np.array(F1).T, columns=[feat])\n",
    "            \n",
    "#             res_f1.append(df_F1)\n",
    "#         res_F1n = pd.concat(res_f1, axis=1)\n",
    "#         res_F1n.loc[:,\"num\"]=num\n",
    "#         res_F1n.loc[:,\"classe\"] = [\"OPT\", \"NC\", \"SOPT\", \"NVA\"]\n",
    "#         results.append(res_F1n)\n",
    "#     print(results[0])\n",
    "#     df_metrics = pd.concat(results, ignore_index=True)\n",
    "#     df_metrics.index = range(len(df_metrics))\n",
    "#     return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prédiction 2 classes, en local\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT =DecisionTreeClassifier(min_samples_leaf=17,max_depth= 10, min_samples_split= 9)\n",
    "\n",
    "df_amp_train, df_amp_test, df_tsv_train, df_tsv_test = train_test_amp_tsv(DF_amplicon, DF_tsv, \"classe\", 0.3, DT)\n",
    "\n",
    "#création des databases finales\n",
    "train = create_var_glob_tot(df_amp_train, df_tsv_train)\n",
    "test = create_var_glob_tot(df_amp_test, df_tsv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train, index_test = create_df_kfold(DF_amplicon, df_am, \"type\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf1 =DecisionTreeClassifier(min_samples_leaf=17,max_depth= 10, min_samples_split= 9)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# clf2 = RandomForestClassifier(n_estimators= 50)\n",
    "clf2 =DecisionTreeClassifier(min_samples_leaf=17,max_depth= 10, min_samples_split= 9)\n",
    "\n",
    "def get_results(DF_amplicon, DF_tsv, index_train, index_test, clf1, clf2):\n",
    "    résultats = []\n",
    "    for i in range(5):\n",
    "        train_index = index_train[i]\n",
    "        test_index = index_test[i]\n",
    "        df_amp_train, df_amp_test, df_tsv_train, df_tsv_test = train_test_amp_tsv(DF_amplicon, DF_tsv, train_index, test_index, clf1)\n",
    "        train = create_var_glob_tot(df_amp_train, df_tsv_train)\n",
    "        test = create_var_glob_tot(df_amp_test, df_tsv_test)\n",
    "        pre = get_pred(train, test, clf2)\n",
    "        pre.loc[:,\"fold\"] = i\n",
    "        résultats.append(pre)\n",
    "    res = pd.concat(résultats)\n",
    "    res.index = range(len(res))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "resul2 = get_results(DF_amplicon, DF_tsv, index_train, index_test, clf1, clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resul[resul[\"fold\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_all</th>\n",
       "      <th>pred_amplicon</th>\n",
       "      <th>pred_tsv</th>\n",
       "      <th>pred_Pearson</th>\n",
       "      <th>pred_Spearman</th>\n",
       "      <th>pred_rfe</th>\n",
       "      <th>pred_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>NVA</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_all pred_amplicon pred_tsv pred_Pearson pred_Spearman pred_rfe  \\\n",
       "0       SOPT          SOPT     SOPT         SOPT          SOPT     SOPT   \n",
       "1       SOPT          SOPT     SOPT         SOPT          SOPT     SOPT   \n",
       "2         NC            NC       NC           NC            NC       NC   \n",
       "3        OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "4        OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "..       ...           ...      ...          ...           ...      ...   \n",
       "593      OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "594     SOPT          SOPT     SOPT         SOPT          SOPT     SOPT   \n",
       "595      NVA          SOPT      NVA          NVA           NVA      NVA   \n",
       "596       NC            NC       NC           NC            NC       NC   \n",
       "597      OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "\n",
       "    pred_rf  \n",
       "0      SOPT  \n",
       "1      SOPT  \n",
       "2        NC  \n",
       "3       OPT  \n",
       "4       OPT  \n",
       "..      ...  \n",
       "593     OPT  \n",
       "594    SOPT  \n",
       "595     NVA  \n",
       "596      NC  \n",
       "597     OPT  \n",
       "\n",
       "[598 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul[[\"pred_all\", \"pred_amplicon\", \"pred_tsv\", \"pred_Pearson\", \"pred_Spearman\", \"pred_rfe\", \"pred_rf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvalue      0.057373046875\n",
      "statistic   3.0\n"
     ]
    }
   ],
   "source": [
    "macnemar(resul2[\"pred_rfe\"], resul2[\"pred_all\"], resul2[\"classe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95373665, 0.        , 0.03914591, 0.00711744],\n",
       "       [0.        , 0.93975904, 0.06024096, 0.        ],\n",
       "       [0.09493671, 0.08227848, 0.74050633, 0.08227848],\n",
       "       [0.02631579, 0.        , 0.02631579, 0.94736842]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(resul2[\"classe\"], resul2[\"pred_all\"], normalize=\"true\", labels=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94035088, 0.        , 0.08148148, 0.02298851],\n",
       "       [0.        , 0.85714286, 0.03703704, 0.        ],\n",
       "       [0.05263158, 0.14285714, 0.86666667, 0.14942529],\n",
       "       [0.00701754, 0.        , 0.01481481, 0.82758621]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(resul2[\"classe\"], resul2[\"pred_all\"], normalize=\"pred\", labels=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97841727, 0.        , 0.05625   , 0.        ],\n",
       "       [0.        , 0.90804598, 0.025     , 0.        ],\n",
       "       [0.01438849, 0.09195402, 0.90625   , 0.01369863],\n",
       "       [0.00719424, 0.        , 0.0125    , 0.98630137]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(resul[\"classe\"], resul[\"pred_all\"], normalize=\"pred\", labels=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_all</th>\n",
       "      <th>pred_amplicon</th>\n",
       "      <th>pred_tsv</th>\n",
       "      <th>pred_Pearson</th>\n",
       "      <th>pred_Spearman</th>\n",
       "      <th>pred_rfe</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>classe</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>NVA</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>NVA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>NVA</td>\n",
       "      <td>OPT</td>\n",
       "      <td>NVA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_all pred_amplicon pred_tsv pred_Pearson pred_Spearman pred_rfe  \\\n",
       "89       OPT           OPT      OPT          NVA           OPT      OPT   \n",
       "117      OPT           OPT      OPT          OPT           OPT      NVA   \n",
       "\n",
       "    pred_rf classe  fold  \n",
       "89      OPT    NVA     0  \n",
       "117     OPT    NVA     0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resul[(resul[\"classe\"]==\"NVA\") & (resul[\"pred_all\"]==\"OPT\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordre = index_test\n",
    "ordre[0][117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "ordre_col = list(itertools.chain.from_iterable(ordre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resu = resul\n",
    "df_resu.loc[:,\"ordre1\"]=ordre_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_all</th>\n",
       "      <th>pred_amplicon</th>\n",
       "      <th>pred_tsv</th>\n",
       "      <th>pred_Pearson</th>\n",
       "      <th>pred_Spearman</th>\n",
       "      <th>pred_rfe</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>classe</th>\n",
       "      <th>fold</th>\n",
       "      <th>ordre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>NC</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>NVA</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>1</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>OPT</td>\n",
       "      <td>NVA</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>3</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>OPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>OPT</td>\n",
       "      <td>SOPT</td>\n",
       "      <td>1</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_all pred_amplicon pred_tsv pred_Pearson pred_Spearman pred_rfe  \\\n",
       "0        OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "1        OPT           OPT     SOPT          OPT           OPT      OPT   \n",
       "2       SOPT          SOPT     SOPT         SOPT          SOPT     SOPT   \n",
       "3         NC            NC       NC           NC            NC       NC   \n",
       "4        NVA           NVA      NVA          NVA           NVA      NVA   \n",
       "..       ...           ...      ...          ...           ...      ...   \n",
       "593      OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "594      OPT           OPT      OPT          OPT           OPT      OPT   \n",
       "595      OPT           NVA      OPT          OPT           OPT      OPT   \n",
       "596     SOPT          SOPT      OPT         SOPT          SOPT     SOPT   \n",
       "597      OPT          SOPT      OPT          OPT           OPT      OPT   \n",
       "\n",
       "    pred_rf classe  fold  ordre1  \n",
       "0       OPT    OPT     2       0  \n",
       "1       OPT    OPT     1       1  \n",
       "2      SOPT   SOPT     0       2  \n",
       "3        NC     NC     3       3  \n",
       "4       NVA    NVA     3       4  \n",
       "..      ...    ...   ...     ...  \n",
       "593     OPT    OPT     1     593  \n",
       "594     OPT    OPT     1     594  \n",
       "595     OPT    OPT     0     595  \n",
       "596    SOPT   SOPT     3     596  \n",
       "597     OPT   SOPT     1     597  \n",
       "\n",
       "[598 rows x 10 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resu = df_resu.sort_values(\"ordre1\")\n",
    "df_resu.index = range(len(df_resu))\n",
    "df_resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resul_final = pd.concat([df_am, df_resu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[:,~df.columns.duplicated()]\n",
    "df_resul_final = df_resul_final.loc[:,~df_resul_final.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resul_final.to_csv(\"résultats_final_info_kfold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resul.to_csv(\"résultats_final_kfold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.19650\n",
       "1      0.16375\n",
       "2      0.14500\n",
       "3      0.00550\n",
       "4      0.00500\n",
       "        ...   \n",
       "474    0.28775\n",
       "475    0.51400\n",
       "476    0.39425\n",
       "477    0.29950\n",
       "478    0.34600\n",
       "Name: Allele Cov_norm_median, Length: 479, dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Allele Cov_norm_median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='classe', ylabel='Quality_norm_median'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(data=train, y=\"Quality_norm_median\", x=\"classe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'SOPT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19288/2182119544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontingency_tables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcochrans_q\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcochrans_q\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresul\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pred_all\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_amplicon\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_Pearson\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_Spearman\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_rfe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_rf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\statsmodels\\stats\\contingency_tables.py\u001b[0m in \u001b[0;36mcochrans_q\u001b[1;34m(x, return_object)\u001b[0m\n\u001b[0;32m   1393\u001b[0m     \"\"\"\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m     \u001b[0mgruni\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m     \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'SOPT'"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import cochrans_q\n",
    "cochrans_q(resul[[\"pred_all\", \"pred_amplicon\", \"pred_tsv\", \"pred_Pearson\", \"pred_Spearman\", \"pred_rfe\", \"pred_rf\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators= 50)\n",
    "\n",
    "feat = select_features(\"all\")\n",
    "\n",
    "clf.fit(train[feat], train[\"classe\"])\n",
    "pred = clf.predict(test[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fa = F1score(confusion_matrix(pre[pre[\"num\"]==0][\"classe\"], pre[pre[\"num\"]==0][\"pred_all\"], normalize=\"true\", labels=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OPT</th>\n",
       "      <td>0.933681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NC</th>\n",
       "      <td>0.915872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOPT</th>\n",
       "      <td>0.894994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVA</th>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_all\n",
       "OPT   0.933681\n",
       "NC    0.915872\n",
       "SOPT  0.894994\n",
       "NVA   0.954545"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(fa, index=[\"OPT\", \"NC\", \"SOPT\", \"NVA\"], columns=[\"pred_all\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyse locale (déja faite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_imp_DT</th>\n",
       "      <th>feat_imp_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gc_percent</th>\n",
       "      <td>0.025298</td>\n",
       "      <td>0.044892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cov500_percent</th>\n",
       "      <td>0.935296</td>\n",
       "      <td>0.584198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwd_e2e_percent</th>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.103293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_e2e_percent</th>\n",
       "      <td>0.011626</td>\n",
       "      <td>0.115837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cov20_percent</th>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.011213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cov100_percent</th>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.104602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contig_length</th>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.035964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feat_imp_DT  feat_imp_RF\n",
       "gc_percent          0.025298     0.044892\n",
       "cov500_percent      0.935296     0.584198\n",
       "fwd_e2e_percent     0.007623     0.103293\n",
       "rev_e2e_percent     0.011626     0.115837\n",
       "cov20_percent       0.000252     0.011213\n",
       "cov100_percent      0.007974     0.104602\n",
       "contig_length       0.011931     0.035964"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features importance for locale models\n",
    "New_var1 = ['gc_percent', 'cov500_percent', 'fwd_e2e_percent', 'rev_e2e_percent', 'cov20_percent', 'cov100_percent', 'contig_length']\n",
    "\n",
    "feat_impdt = pd.DataFrame(DT.feature_importances_, index=New_var1, columns=[\"feat_imp_DT\"])\n",
    "# feat_impdt = feat_impdt.sort_values(0)\n",
    "\n",
    "feat_imprf = pd.DataFrame(RF.feature_importances_, index=New_var1, columns=[\"feat_imp_RF\"])\n",
    "# feat_imprf = feat_imprf.sort_values(0)\n",
    "\n",
    "feat_imp = pd.concat([feat_impdt, feat_imprf], axis=1)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae0c165457b802f0b012063a7cdde1edfba027a28a70c7da628e688424df5479"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
